{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66138808-a613-45cc-82d4-5826b511bb51",
   "metadata": {},
   "source": [
    "Test if the ShiftFormer can do more things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed32d986-818c-4103-aabf-ed7400bc9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097f23a1-3839-4e79-a81a-e07313045c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mae_components_no_cls import *\n",
    "import yaml\n",
    "from PIL import Image,ImageDraw\n",
    "from mae_dataset import get_miniImageNetDataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import json\n",
    "import utils\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.transforms import functional\n",
    "from environment import StaticImgEnv\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2, 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36d5799-b2a9-47c3-97be-05ea7e74f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml_config(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config = read_yaml_config('config_shift.yaml')\n",
    "\n",
    "def Transpose(img):\n",
    "    img=torch.clip(img,0.0,1.0)\n",
    "    test_img=functional.to_pil_image(img)\n",
    "\n",
    "    return test_img\n",
    "\n",
    "def draw_focus(img, x, y, patch_size):\n",
    "    imdraw = ImageDraw.Draw(img)\n",
    "    imdraw.rectangle((y,x,y+patch_size,x+patch_size), outline=\"blue\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba975786-2ebe-451d-8dc9-864f99f39b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root=\"COCOSearch18\"\n",
    "with open(os.path.join(dataset_root,\n",
    "               'coco_search18_fixations_TP_train_split1.json'#'coco_search18_fixations_TP_train.json'\n",
    "               )) as json_file:\n",
    "    human_scanpaths_train = json.load(json_file)\n",
    "    \n",
    "with open(os.path.join(dataset_root,\n",
    "               'coco_search18_fixations_TP_validation_split1.json'#'coco_search18_fixations_TP_validation.json'\n",
    "               )) as json_file:\n",
    "    human_scanpaths_valid = json.load(json_file)\n",
    "\n",
    "'''\n",
    "max=0\n",
    "for dict in human_scanpaths_train:\n",
    "    if dict['length']>=max:\n",
    "        max=dict['length']\n",
    "print(max)\n",
    "'''\n",
    "\n",
    "dataset=utils.COCOSearch18(json=human_scanpaths_train,root='COCOSearch18/images',test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4318d57-5772-4e3c-8c52-18ffe9277b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader=DataLoader(dataset,batch_size=64, shuffle=True,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4825d4-9168-419c-913a-97fa26709575",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7720cf46-fca6-49d2-982e-ab1626a7641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_encoder=MaskedViTEncoder(config, 224, 16, embed_dim=512, device=device).to(device)\n",
    "shift_block=ShiftTransformer(config, img_size=224, patch_size=16, embed_dim=512, device=device).to(device)\n",
    "mae_decoder=MaskedViTDecoder(config, 224, 16, encoder_embed_dim=512, decoder_embed_dim=256, device=device, masked_decoder_loss=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "832765e0-972a-4423-afaf-3e45eae8605f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedViTDecoder(\n",
       "  (encoder_to_decoder): Linear(in_features=512, out_features=256, bias=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (act2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.014285714365541935)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (act2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.02857142873108387)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (act2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.04285714402794838)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (act2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.05714285746216774)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (act2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0714285746216774)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (act2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08571428805589676)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (act2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.10000000149011612)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (act2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (decoder_pred): Linear(in_features=256, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_encoder.load_state_dict(torch.load(\"./mae_log/no_cls/encoder_param.pth\"),strict=False)\n",
    "shift_block.load_state_dict(torch.load(\"./mae_log/shift_test/shift_param_coco.pth\"),strict=False)\n",
    "mae_decoder.load_state_dict(torch.load(\"./mae_log/no_cls/decoder_param.pth\"),strict=False)\n",
    "mae_encoder.eval()\n",
    "shift_block.eval()\n",
    "mae_decoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4a69d2-9990-4a1c-9856-c59f760be126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_dict=[{'params':mae_encoder.parameters()},{'params':mae_decoder.parameters()},{'params':shift_block.parameters()}]\n",
    "param_dict=[{'params':mae_decoder.parameters()}]\n",
    "optimizer = optim.Adam(param_dict, lr=0.00005) #0.0001 for normal training, 0.00005 for finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50d92b6c-0c06-4ca8-9158-2d14a0c18440",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=StaticImgEnv(env_args=config['Environment'],show_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c2c45e8-6428-4170-81de-356c5f2e1572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch:0 0/338 Loss:0.017\n",
      "Epoch:0 20/338 Loss:0.016\n",
      "Epoch:0 40/338 Loss:0.015\n",
      "Epoch:0 60/338 Loss:0.011\n",
      "Epoch:0 80/338 Loss:0.014\n",
      "Epoch:0 100/338 Loss:0.013\n",
      "Epoch:0 120/338 Loss:0.014\n",
      "Epoch:0 140/338 Loss:0.014\n",
      "Epoch:0 160/338 Loss:0.017\n",
      "Epoch:0 180/338 Loss:0.016\n",
      "Epoch:0 200/338 Loss:0.015\n",
      "Epoch:0 220/338 Loss:0.017\n",
      "Epoch:0 240/338 Loss:0.016\n",
      "Epoch:0 260/338 Loss:0.016\n",
      "Epoch:0 280/338 Loss:0.014\n",
      "Epoch:0 300/338 Loss:0.013\n",
      "Epoch:0 320/338 Loss:0.014\n",
      "Epoch:1 0/338 Loss:0.017\n",
      "Epoch:1 20/338 Loss:0.013\n",
      "Epoch:1 40/338 Loss:0.015\n",
      "Epoch:1 60/338 Loss:0.013\n",
      "Epoch:1 80/338 Loss:0.016\n",
      "Epoch:1 100/338 Loss:0.013\n",
      "Epoch:1 120/338 Loss:0.014\n",
      "Epoch:1 140/338 Loss:0.013\n",
      "Epoch:1 160/338 Loss:0.015\n",
      "Epoch:1 180/338 Loss:0.017\n",
      "Epoch:1 200/338 Loss:0.016\n",
      "Epoch:1 220/338 Loss:0.011\n",
      "Epoch:1 240/338 Loss:0.012\n",
      "Epoch:1 260/338 Loss:0.012\n",
      "Epoch:1 280/338 Loss:0.015\n",
      "Epoch:1 300/338 Loss:0.015\n",
      "Epoch:1 320/338 Loss:0.016\n",
      "Epoch:2 0/338 Loss:0.014\n",
      "Epoch:2 20/338 Loss:0.015\n",
      "Epoch:2 40/338 Loss:0.017\n",
      "Epoch:2 60/338 Loss:0.015\n",
      "Epoch:2 80/338 Loss:0.014\n",
      "Epoch:2 100/338 Loss:0.014\n",
      "Epoch:2 120/338 Loss:0.015\n",
      "Epoch:2 140/338 Loss:0.011\n",
      "Epoch:2 160/338 Loss:0.011\n",
      "Epoch:2 180/338 Loss:0.017\n",
      "Epoch:2 200/338 Loss:0.016\n",
      "Epoch:2 220/338 Loss:0.015\n",
      "Epoch:2 240/338 Loss:0.014\n",
      "Epoch:2 260/338 Loss:0.014\n",
      "Epoch:2 280/338 Loss:0.011\n",
      "Epoch:2 300/338 Loss:0.015\n",
      "Epoch:2 320/338 Loss:0.010\n",
      "Epoch:3 0/338 Loss:0.017\n",
      "Epoch:3 20/338 Loss:0.012\n",
      "Epoch:3 40/338 Loss:0.013\n",
      "Epoch:3 60/338 Loss:0.014\n",
      "Epoch:3 80/338 Loss:0.015\n",
      "Epoch:3 100/338 Loss:0.017\n",
      "Epoch:3 120/338 Loss:0.012\n",
      "Epoch:3 140/338 Loss:0.015\n",
      "Epoch:3 160/338 Loss:0.015\n",
      "Epoch:3 180/338 Loss:0.016\n",
      "Epoch:3 200/338 Loss:0.013\n",
      "Epoch:3 220/338 Loss:0.013\n",
      "Epoch:3 240/338 Loss:0.015\n",
      "Epoch:3 260/338 Loss:0.011\n",
      "Epoch:3 280/338 Loss:0.014\n",
      "Epoch:3 300/338 Loss:0.015\n",
      "Epoch:3 320/338 Loss:0.015\n",
      "Epoch:4 0/338 Loss:0.016\n",
      "Epoch:4 20/338 Loss:0.014\n",
      "Epoch:4 40/338 Loss:0.014\n",
      "Epoch:4 60/338 Loss:0.013\n",
      "Epoch:4 80/338 Loss:0.013\n",
      "Epoch:4 100/338 Loss:0.014\n",
      "Epoch:4 120/338 Loss:0.014\n",
      "Epoch:4 140/338 Loss:0.013\n",
      "Epoch:4 160/338 Loss:0.012\n",
      "Epoch:4 180/338 Loss:0.012\n",
      "Epoch:4 200/338 Loss:0.014\n",
      "Epoch:4 220/338 Loss:0.011\n",
      "Epoch:4 240/338 Loss:0.014\n",
      "Epoch:4 260/338 Loss:0.013\n",
      "Epoch:4 280/338 Loss:0.015\n",
      "Epoch:4 300/338 Loss:0.015\n",
      "Epoch:4 320/338 Loss:0.012\n",
      "Epoch:5 0/338 Loss:0.013\n",
      "Epoch:5 20/338 Loss:0.013\n",
      "Epoch:5 40/338 Loss:0.014\n",
      "Epoch:5 60/338 Loss:0.013\n",
      "Epoch:5 80/338 Loss:0.012\n",
      "Epoch:5 100/338 Loss:0.014\n",
      "Epoch:5 120/338 Loss:0.014\n",
      "Epoch:5 140/338 Loss:0.014\n",
      "Epoch:5 160/338 Loss:0.015\n",
      "Epoch:5 180/338 Loss:0.012\n",
      "Epoch:5 200/338 Loss:0.013\n",
      "Epoch:5 220/338 Loss:0.016\n",
      "Epoch:5 240/338 Loss:0.013\n",
      "Epoch:5 260/338 Loss:0.013\n",
      "Epoch:5 280/338 Loss:0.011\n",
      "Epoch:5 300/338 Loss:0.013\n",
      "Epoch:5 320/338 Loss:0.012\n",
      "Epoch:6 0/338 Loss:0.015\n",
      "Epoch:6 20/338 Loss:0.011\n",
      "Epoch:6 40/338 Loss:0.012\n",
      "Epoch:6 60/338 Loss:0.013\n",
      "Epoch:6 80/338 Loss:0.010\n",
      "Epoch:6 100/338 Loss:0.011\n",
      "Epoch:6 120/338 Loss:0.013\n",
      "Epoch:6 140/338 Loss:0.014\n",
      "Epoch:6 160/338 Loss:0.014\n",
      "Epoch:6 180/338 Loss:0.014\n",
      "Epoch:6 200/338 Loss:0.012\n",
      "Epoch:6 220/338 Loss:0.014\n",
      "Epoch:6 240/338 Loss:0.012\n",
      "Epoch:6 260/338 Loss:0.013\n",
      "Epoch:6 280/338 Loss:0.013\n",
      "Epoch:6 300/338 Loss:0.011\n",
      "Epoch:6 320/338 Loss:0.010\n",
      "Epoch:7 0/338 Loss:0.014\n",
      "Epoch:7 20/338 Loss:0.012\n",
      "Epoch:7 40/338 Loss:0.012\n",
      "Epoch:7 60/338 Loss:0.014\n",
      "Epoch:7 80/338 Loss:0.013\n",
      "Epoch:7 100/338 Loss:0.012\n",
      "Epoch:7 120/338 Loss:0.013\n",
      "Epoch:7 140/338 Loss:0.015\n",
      "Epoch:7 160/338 Loss:0.011\n",
      "Epoch:7 180/338 Loss:0.014\n",
      "Epoch:7 200/338 Loss:0.016\n",
      "Epoch:7 220/338 Loss:0.012\n",
      "Epoch:7 240/338 Loss:0.012\n",
      "Epoch:7 260/338 Loss:0.013\n",
      "Epoch:7 280/338 Loss:0.012\n",
      "Epoch:7 300/338 Loss:0.012\n",
      "Epoch:7 320/338 Loss:0.013\n",
      "Epoch:8 0/338 Loss:0.012\n",
      "Epoch:8 20/338 Loss:0.013\n",
      "Epoch:8 40/338 Loss:0.013\n",
      "Epoch:8 60/338 Loss:0.013\n",
      "Epoch:8 80/338 Loss:0.015\n",
      "Epoch:8 100/338 Loss:0.012\n",
      "Epoch:8 120/338 Loss:0.015\n",
      "Epoch:8 140/338 Loss:0.016\n",
      "Epoch:8 160/338 Loss:0.011\n",
      "Epoch:8 180/338 Loss:0.019\n",
      "Epoch:8 200/338 Loss:0.012\n",
      "Epoch:8 220/338 Loss:0.012\n",
      "Epoch:8 240/338 Loss:0.013\n",
      "Epoch:8 260/338 Loss:0.015\n",
      "Epoch:8 280/338 Loss:0.015\n",
      "Epoch:8 300/338 Loss:0.015\n",
      "Epoch:8 320/338 Loss:0.013\n",
      "Epoch:9 0/338 Loss:0.013\n",
      "Epoch:9 20/338 Loss:0.013\n",
      "Epoch:9 40/338 Loss:0.015\n",
      "Epoch:9 60/338 Loss:0.016\n",
      "Epoch:9 80/338 Loss:0.015\n",
      "Epoch:9 100/338 Loss:0.012\n",
      "Epoch:9 120/338 Loss:0.014\n",
      "Epoch:9 140/338 Loss:0.013\n",
      "Epoch:9 160/338 Loss:0.012\n",
      "Epoch:9 180/338 Loss:0.015\n",
      "Epoch:9 200/338 Loss:0.015\n",
      "Epoch:9 220/338 Loss:0.015\n",
      "Epoch:9 240/338 Loss:0.014\n",
      "Epoch:9 260/338 Loss:0.012\n",
      "Epoch:9 280/338 Loss:0.014\n",
      "Epoch:9 300/338 Loss:0.013\n",
      "Epoch:9 320/338 Loss:0.012\n",
      "Epoch:10 0/338 Loss:0.011\n",
      "Epoch:10 20/338 Loss:0.016\n",
      "Epoch:10 40/338 Loss:0.012\n",
      "Epoch:10 60/338 Loss:0.010\n",
      "Epoch:10 80/338 Loss:0.012\n",
      "Epoch:10 100/338 Loss:0.013\n",
      "Epoch:10 120/338 Loss:0.011\n",
      "Epoch:10 140/338 Loss:0.012\n",
      "Epoch:10 160/338 Loss:0.013\n",
      "Epoch:10 180/338 Loss:0.012\n",
      "Epoch:10 200/338 Loss:0.010\n",
      "Epoch:10 220/338 Loss:0.016\n",
      "Epoch:10 240/338 Loss:0.012\n",
      "Epoch:10 260/338 Loss:0.015\n",
      "Epoch:10 280/338 Loss:0.013\n",
      "Epoch:10 300/338 Loss:0.013\n",
      "Epoch:10 320/338 Loss:0.010\n",
      "Epoch:11 0/338 Loss:0.013\n",
      "Epoch:11 20/338 Loss:0.016\n",
      "Epoch:11 40/338 Loss:0.011\n",
      "Epoch:11 60/338 Loss:0.015\n",
      "Epoch:11 80/338 Loss:0.014\n",
      "Epoch:11 100/338 Loss:0.011\n",
      "Epoch:11 120/338 Loss:0.010\n",
      "Epoch:11 140/338 Loss:0.014\n",
      "Epoch:11 160/338 Loss:0.012\n",
      "Epoch:11 180/338 Loss:0.014\n",
      "Epoch:11 200/338 Loss:0.013\n",
      "Epoch:11 220/338 Loss:0.013\n",
      "Epoch:11 240/338 Loss:0.014\n",
      "Epoch:11 260/338 Loss:0.016\n",
      "Epoch:11 280/338 Loss:0.011\n",
      "Epoch:11 300/338 Loss:0.014\n",
      "Epoch:11 320/338 Loss:0.009\n",
      "Epoch:12 0/338 Loss:0.013\n",
      "Epoch:12 20/338 Loss:0.012\n",
      "Epoch:12 40/338 Loss:0.011\n",
      "Epoch:12 60/338 Loss:0.009\n",
      "Epoch:12 80/338 Loss:0.015\n",
      "Epoch:12 100/338 Loss:0.013\n",
      "Epoch:12 120/338 Loss:0.013\n",
      "Epoch:12 140/338 Loss:0.014\n",
      "Epoch:12 160/338 Loss:0.010\n",
      "Epoch:12 180/338 Loss:0.014\n",
      "Epoch:12 200/338 Loss:0.013\n",
      "Epoch:12 220/338 Loss:0.010\n",
      "Epoch:12 240/338 Loss:0.015\n",
      "Epoch:12 260/338 Loss:0.012\n",
      "Epoch:12 280/338 Loss:0.012\n",
      "Epoch:12 300/338 Loss:0.012\n",
      "Epoch:12 320/338 Loss:0.010\n",
      "Epoch:13 0/338 Loss:0.014\n",
      "Epoch:13 20/338 Loss:0.012\n",
      "Epoch:13 40/338 Loss:0.013\n",
      "Epoch:13 60/338 Loss:0.013\n",
      "Epoch:13 80/338 Loss:0.013\n",
      "Epoch:13 100/338 Loss:0.013\n",
      "Epoch:13 120/338 Loss:0.012\n",
      "Epoch:13 140/338 Loss:0.015\n",
      "Epoch:13 160/338 Loss:0.017\n",
      "Epoch:13 180/338 Loss:0.013\n",
      "Epoch:13 200/338 Loss:0.013\n",
      "Epoch:13 220/338 Loss:0.018\n",
      "Epoch:13 240/338 Loss:0.012\n",
      "Epoch:13 260/338 Loss:0.012\n",
      "Epoch:13 280/338 Loss:0.014\n",
      "Epoch:13 300/338 Loss:0.010\n",
      "Epoch:13 320/338 Loss:0.010\n",
      "Epoch:14 0/338 Loss:0.012\n",
      "Epoch:14 20/338 Loss:0.011\n",
      "Epoch:14 40/338 Loss:0.012\n",
      "Epoch:14 60/338 Loss:0.013\n",
      "Epoch:14 80/338 Loss:0.014\n",
      "Epoch:14 100/338 Loss:0.010\n",
      "Epoch:14 120/338 Loss:0.017\n",
      "Epoch:14 140/338 Loss:0.013\n",
      "Epoch:14 160/338 Loss:0.012\n",
      "Epoch:14 180/338 Loss:0.013\n",
      "Epoch:14 200/338 Loss:0.014\n",
      "Epoch:14 220/338 Loss:0.014\n",
      "Epoch:14 240/338 Loss:0.014\n",
      "Epoch:14 260/338 Loss:0.012\n",
      "Epoch:14 280/338 Loss:0.017\n",
      "Epoch:14 300/338 Loss:0.013\n",
      "Epoch:14 320/338 Loss:0.013\n",
      "Epoch:15 0/338 Loss:0.013\n",
      "Epoch:15 20/338 Loss:0.013\n",
      "Epoch:15 40/338 Loss:0.011\n",
      "Epoch:15 60/338 Loss:0.012\n",
      "Epoch:15 80/338 Loss:0.012\n",
      "Epoch:15 100/338 Loss:0.014\n",
      "Epoch:15 120/338 Loss:0.013\n",
      "Epoch:15 140/338 Loss:0.014\n",
      "Epoch:15 160/338 Loss:0.011\n",
      "Epoch:15 180/338 Loss:0.012\n",
      "Epoch:15 200/338 Loss:0.016\n",
      "Epoch:15 220/338 Loss:0.014\n",
      "Epoch:15 240/338 Loss:0.014\n",
      "Epoch:15 260/338 Loss:0.012\n",
      "Epoch:15 280/338 Loss:0.013\n",
      "Epoch:15 300/338 Loss:0.012\n",
      "Epoch:15 320/338 Loss:0.012\n",
      "Epoch:16 0/338 Loss:0.016\n",
      "Epoch:16 20/338 Loss:0.014\n",
      "Epoch:16 40/338 Loss:0.016\n",
      "Epoch:16 60/338 Loss:0.014\n",
      "Epoch:16 80/338 Loss:0.013\n",
      "Epoch:16 100/338 Loss:0.013\n",
      "Epoch:16 120/338 Loss:0.010\n",
      "Epoch:16 140/338 Loss:0.013\n",
      "Epoch:16 160/338 Loss:0.013\n",
      "Epoch:16 180/338 Loss:0.014\n",
      "Epoch:16 200/338 Loss:0.012\n",
      "Epoch:16 220/338 Loss:0.013\n",
      "Epoch:16 240/338 Loss:0.013\n",
      "Epoch:16 260/338 Loss:0.014\n",
      "Epoch:16 280/338 Loss:0.013\n",
      "Epoch:16 300/338 Loss:0.015\n",
      "Epoch:16 320/338 Loss:0.012\n",
      "Epoch:17 0/338 Loss:0.014\n",
      "Epoch:17 20/338 Loss:0.014\n",
      "Epoch:17 40/338 Loss:0.012\n",
      "Epoch:17 60/338 Loss:0.013\n",
      "Epoch:17 80/338 Loss:0.012\n",
      "Epoch:17 100/338 Loss:0.014\n",
      "Epoch:17 120/338 Loss:0.014\n",
      "Epoch:17 140/338 Loss:0.013\n",
      "Epoch:17 160/338 Loss:0.012\n",
      "Epoch:17 180/338 Loss:0.016\n",
      "Epoch:17 200/338 Loss:0.011\n",
      "Epoch:17 220/338 Loss:0.013\n",
      "Epoch:17 240/338 Loss:0.013\n",
      "Epoch:17 260/338 Loss:0.012\n",
      "Epoch:17 280/338 Loss:0.011\n",
      "Epoch:17 300/338 Loss:0.013\n",
      "Epoch:17 320/338 Loss:0.012\n",
      "Epoch:18 0/338 Loss:0.016\n",
      "Epoch:18 20/338 Loss:0.013\n",
      "Epoch:18 40/338 Loss:0.015\n",
      "Epoch:18 60/338 Loss:0.015\n",
      "Epoch:18 80/338 Loss:0.012\n",
      "Epoch:18 100/338 Loss:0.010\n",
      "Epoch:18 120/338 Loss:0.011\n",
      "Epoch:18 140/338 Loss:0.013\n",
      "Epoch:18 160/338 Loss:0.013\n",
      "Epoch:18 180/338 Loss:0.011\n",
      "Epoch:18 200/338 Loss:0.013\n",
      "Epoch:18 220/338 Loss:0.012\n",
      "Epoch:18 240/338 Loss:0.012\n",
      "Epoch:18 260/338 Loss:0.012\n",
      "Epoch:18 280/338 Loss:0.012\n",
      "Epoch:18 300/338 Loss:0.014\n",
      "Epoch:18 320/338 Loss:0.013\n",
      "Epoch:19 0/338 Loss:0.013\n",
      "Epoch:19 20/338 Loss:0.011\n",
      "Epoch:19 40/338 Loss:0.012\n",
      "Epoch:19 60/338 Loss:0.013\n",
      "Epoch:19 80/338 Loss:0.012\n",
      "Epoch:19 100/338 Loss:0.014\n",
      "Epoch:19 120/338 Loss:0.014\n",
      "Epoch:19 140/338 Loss:0.009\n",
      "Epoch:19 160/338 Loss:0.013\n",
      "Epoch:19 180/338 Loss:0.013\n",
      "Epoch:19 200/338 Loss:0.013\n",
      "Epoch:19 220/338 Loss:0.012\n",
      "Epoch:19 240/338 Loss:0.012\n",
      "Epoch:19 260/338 Loss:0.014\n",
      "Epoch:19 280/338 Loss:0.014\n",
      "Epoch:19 300/338 Loss:0.011\n",
      "Epoch:19 320/338 Loss:0.013\n",
      "Epoch:20 0/338 Loss:0.013\n",
      "Epoch:20 20/338 Loss:0.011\n",
      "Epoch:20 40/338 Loss:0.010\n",
      "Epoch:20 60/338 Loss:0.012\n",
      "Epoch:20 80/338 Loss:0.015\n",
      "Epoch:20 100/338 Loss:0.014\n",
      "Epoch:20 120/338 Loss:0.013\n",
      "Epoch:20 140/338 Loss:0.011\n",
      "Epoch:20 160/338 Loss:0.011\n",
      "Epoch:20 180/338 Loss:0.010\n",
      "Epoch:20 200/338 Loss:0.012\n",
      "Epoch:20 220/338 Loss:0.013\n",
      "Epoch:20 240/338 Loss:0.011\n",
      "Epoch:20 260/338 Loss:0.013\n",
      "Epoch:20 280/338 Loss:0.011\n",
      "Epoch:20 300/338 Loss:0.012\n",
      "Epoch:20 320/338 Loss:0.013\n",
      "Epoch:21 0/338 Loss:0.013\n",
      "Epoch:21 20/338 Loss:0.012\n",
      "Epoch:21 40/338 Loss:0.013\n",
      "Epoch:21 60/338 Loss:0.012\n",
      "Epoch:21 80/338 Loss:0.013\n",
      "Epoch:21 100/338 Loss:0.012\n",
      "Epoch:21 120/338 Loss:0.014\n",
      "Epoch:21 140/338 Loss:0.013\n",
      "Epoch:21 160/338 Loss:0.014\n",
      "Epoch:21 180/338 Loss:0.011\n",
      "Epoch:21 200/338 Loss:0.014\n",
      "Epoch:21 220/338 Loss:0.013\n",
      "Epoch:21 240/338 Loss:0.010\n",
      "Epoch:21 260/338 Loss:0.011\n",
      "Epoch:21 280/338 Loss:0.010\n",
      "Epoch:21 300/338 Loss:0.013\n",
      "Epoch:21 320/338 Loss:0.013\n",
      "Epoch:22 0/338 Loss:0.017\n",
      "Epoch:22 20/338 Loss:0.015\n",
      "Epoch:22 40/338 Loss:0.011\n",
      "Epoch:22 60/338 Loss:0.010\n",
      "Epoch:22 80/338 Loss:0.013\n",
      "Epoch:22 100/338 Loss:0.010\n",
      "Epoch:22 120/338 Loss:0.013\n",
      "Epoch:22 140/338 Loss:0.011\n",
      "Epoch:22 160/338 Loss:0.013\n",
      "Epoch:22 180/338 Loss:0.012\n",
      "Epoch:22 200/338 Loss:0.012\n",
      "Epoch:22 220/338 Loss:0.011\n",
      "Epoch:22 240/338 Loss:0.013\n",
      "Epoch:22 260/338 Loss:0.009\n",
      "Epoch:22 280/338 Loss:0.012\n",
      "Epoch:22 300/338 Loss:0.013\n",
      "Epoch:22 320/338 Loss:0.013\n",
      "Epoch:23 0/338 Loss:0.014\n",
      "Epoch:23 20/338 Loss:0.012\n",
      "Epoch:23 40/338 Loss:0.013\n",
      "Epoch:23 60/338 Loss:0.010\n",
      "Epoch:23 80/338 Loss:0.012\n",
      "Epoch:23 100/338 Loss:0.010\n",
      "Epoch:23 120/338 Loss:0.010\n",
      "Epoch:23 140/338 Loss:0.014\n",
      "Epoch:23 160/338 Loss:0.009\n",
      "Epoch:23 180/338 Loss:0.012\n",
      "Epoch:23 200/338 Loss:0.011\n",
      "Epoch:23 220/338 Loss:0.012\n",
      "Epoch:23 240/338 Loss:0.012\n",
      "Epoch:23 260/338 Loss:0.014\n",
      "Epoch:23 280/338 Loss:0.012\n",
      "Epoch:23 300/338 Loss:0.011\n",
      "Epoch:23 320/338 Loss:0.013\n",
      "Epoch:24 0/338 Loss:0.011\n",
      "Epoch:24 20/338 Loss:0.015\n",
      "Epoch:24 40/338 Loss:0.013\n",
      "Epoch:24 60/338 Loss:0.017\n",
      "Epoch:24 80/338 Loss:0.012\n",
      "Epoch:24 100/338 Loss:0.012\n",
      "Epoch:24 120/338 Loss:0.011\n",
      "Epoch:24 140/338 Loss:0.011\n",
      "Epoch:24 160/338 Loss:0.012\n",
      "Epoch:24 180/338 Loss:0.013\n",
      "Epoch:24 200/338 Loss:0.012\n",
      "Epoch:24 220/338 Loss:0.011\n",
      "Epoch:24 240/338 Loss:0.011\n",
      "Epoch:24 260/338 Loss:0.009\n",
      "Epoch:24 280/338 Loss:0.013\n",
      "Epoch:24 300/338 Loss:0.014\n",
      "Epoch:24 320/338 Loss:0.010\n",
      "Epoch:25 0/338 Loss:0.015\n",
      "Epoch:25 20/338 Loss:0.014\n",
      "Epoch:25 40/338 Loss:0.013\n",
      "Epoch:25 60/338 Loss:0.012\n",
      "Epoch:25 80/338 Loss:0.013\n",
      "Epoch:25 100/338 Loss:0.014\n",
      "Epoch:25 120/338 Loss:0.011\n",
      "Epoch:25 140/338 Loss:0.011\n",
      "Epoch:25 160/338 Loss:0.011\n",
      "Epoch:25 180/338 Loss:0.016\n",
      "Epoch:25 200/338 Loss:0.015\n",
      "Epoch:25 220/338 Loss:0.015\n",
      "Epoch:25 240/338 Loss:0.013\n",
      "Epoch:25 260/338 Loss:0.015\n",
      "Epoch:25 280/338 Loss:0.011\n",
      "Epoch:25 300/338 Loss:0.012\n",
      "Epoch:25 320/338 Loss:0.013\n",
      "Epoch:26 0/338 Loss:0.012\n",
      "Epoch:26 20/338 Loss:0.012\n",
      "Epoch:26 40/338 Loss:0.013\n",
      "Epoch:26 60/338 Loss:0.014\n",
      "Epoch:26 80/338 Loss:0.015\n",
      "Epoch:26 100/338 Loss:0.012\n",
      "Epoch:26 120/338 Loss:0.013\n",
      "Epoch:26 140/338 Loss:0.010\n",
      "Epoch:26 160/338 Loss:0.012\n",
      "Epoch:26 180/338 Loss:0.012\n",
      "Epoch:26 200/338 Loss:0.011\n",
      "Epoch:26 220/338 Loss:0.011\n",
      "Epoch:26 240/338 Loss:0.013\n",
      "Epoch:26 260/338 Loss:0.010\n",
      "Epoch:26 280/338 Loss:0.014\n",
      "Epoch:26 300/338 Loss:0.013\n",
      "Epoch:26 320/338 Loss:0.013\n",
      "Epoch:27 0/338 Loss:0.011\n",
      "Epoch:27 20/338 Loss:0.011\n",
      "Epoch:27 40/338 Loss:0.014\n",
      "Epoch:27 60/338 Loss:0.013\n",
      "Epoch:27 80/338 Loss:0.009\n",
      "Epoch:27 100/338 Loss:0.014\n",
      "Epoch:27 120/338 Loss:0.013\n",
      "Epoch:27 140/338 Loss:0.013\n",
      "Epoch:27 160/338 Loss:0.014\n",
      "Epoch:27 180/338 Loss:0.012\n",
      "Epoch:27 200/338 Loss:0.011\n",
      "Epoch:27 220/338 Loss:0.013\n",
      "Epoch:27 240/338 Loss:0.013\n",
      "Epoch:27 260/338 Loss:0.011\n",
      "Epoch:27 280/338 Loss:0.012\n",
      "Epoch:27 300/338 Loss:0.013\n",
      "Epoch:27 320/338 Loss:0.011\n",
      "Epoch:28 0/338 Loss:0.012\n",
      "Epoch:28 20/338 Loss:0.011\n",
      "Epoch:28 40/338 Loss:0.012\n",
      "Epoch:28 60/338 Loss:0.010\n",
      "Epoch:28 80/338 Loss:0.010\n",
      "Epoch:28 100/338 Loss:0.011\n",
      "Epoch:28 120/338 Loss:0.014\n",
      "Epoch:28 140/338 Loss:0.013\n",
      "Epoch:28 160/338 Loss:0.011\n",
      "Epoch:28 180/338 Loss:0.013\n",
      "Epoch:28 200/338 Loss:0.014\n",
      "Epoch:28 220/338 Loss:0.012\n",
      "Epoch:28 240/338 Loss:0.009\n",
      "Epoch:28 260/338 Loss:0.011\n",
      "Epoch:28 280/338 Loss:0.017\n",
      "Epoch:28 300/338 Loss:0.014\n",
      "Epoch:28 320/338 Loss:0.013\n",
      "Epoch:29 0/338 Loss:0.013\n",
      "Epoch:29 20/338 Loss:0.010\n",
      "Epoch:29 40/338 Loss:0.011\n",
      "Epoch:29 60/338 Loss:0.011\n",
      "Epoch:29 80/338 Loss:0.013\n",
      "Epoch:29 100/338 Loss:0.016\n",
      "Epoch:29 120/338 Loss:0.014\n",
      "Epoch:29 140/338 Loss:0.010\n",
      "Epoch:29 160/338 Loss:0.011\n",
      "Epoch:29 180/338 Loss:0.012\n",
      "Epoch:29 200/338 Loss:0.014\n",
      "Epoch:29 220/338 Loss:0.014\n",
      "Epoch:29 240/338 Loss:0.013\n",
      "Epoch:29 260/338 Loss:0.011\n",
      "Epoch:29 280/338 Loss:0.013\n",
      "Epoch:29 300/338 Loss:0.010\n",
      "Epoch:29 320/338 Loss:0.012\n",
      "Epoch:30 0/338 Loss:0.013\n",
      "Epoch:30 20/338 Loss:0.013\n",
      "Epoch:30 40/338 Loss:0.011\n",
      "Epoch:30 60/338 Loss:0.013\n",
      "Epoch:30 80/338 Loss:0.013\n",
      "Epoch:30 100/338 Loss:0.013\n",
      "Epoch:30 120/338 Loss:0.012\n",
      "Epoch:30 140/338 Loss:0.012\n",
      "Epoch:30 160/338 Loss:0.013\n",
      "Epoch:30 180/338 Loss:0.012\n",
      "Epoch:30 200/338 Loss:0.011\n",
      "Epoch:30 220/338 Loss:0.013\n",
      "Epoch:30 240/338 Loss:0.011\n",
      "Epoch:30 260/338 Loss:0.011\n",
      "Epoch:30 280/338 Loss:0.011\n",
      "Epoch:30 300/338 Loss:0.014\n",
      "Epoch:30 320/338 Loss:0.010\n",
      "Epoch:31 0/338 Loss:0.012\n",
      "Epoch:31 20/338 Loss:0.012\n",
      "Epoch:31 40/338 Loss:0.015\n",
      "Epoch:31 60/338 Loss:0.011\n",
      "Epoch:31 80/338 Loss:0.015\n",
      "Epoch:31 100/338 Loss:0.013\n",
      "Epoch:31 120/338 Loss:0.014\n",
      "Epoch:31 140/338 Loss:0.013\n",
      "Epoch:31 160/338 Loss:0.013\n",
      "Epoch:31 180/338 Loss:0.013\n",
      "Epoch:31 200/338 Loss:0.012\n",
      "Epoch:31 220/338 Loss:0.013\n",
      "Epoch:31 240/338 Loss:0.012\n",
      "Epoch:31 260/338 Loss:0.009\n",
      "Epoch:31 280/338 Loss:0.013\n",
      "Epoch:31 300/338 Loss:0.011\n",
      "Epoch:31 320/338 Loss:0.010\n",
      "Epoch:32 0/338 Loss:0.013\n",
      "Epoch:32 20/338 Loss:0.010\n",
      "Epoch:32 40/338 Loss:0.013\n",
      "Epoch:32 60/338 Loss:0.012\n",
      "Epoch:32 80/338 Loss:0.013\n",
      "Epoch:32 100/338 Loss:0.010\n",
      "Epoch:32 120/338 Loss:0.012\n",
      "Epoch:32 140/338 Loss:0.010\n",
      "Epoch:32 160/338 Loss:0.013\n",
      "Epoch:32 180/338 Loss:0.012\n",
      "Epoch:32 200/338 Loss:0.011\n",
      "Epoch:32 220/338 Loss:0.012\n",
      "Epoch:32 240/338 Loss:0.014\n",
      "Epoch:32 260/338 Loss:0.012\n",
      "Epoch:32 280/338 Loss:0.013\n",
      "Epoch:32 300/338 Loss:0.009\n",
      "Epoch:32 320/338 Loss:0.012\n",
      "Epoch:33 0/338 Loss:0.013\n",
      "Epoch:33 20/338 Loss:0.016\n",
      "Epoch:33 40/338 Loss:0.012\n",
      "Epoch:33 60/338 Loss:0.013\n",
      "Epoch:33 80/338 Loss:0.011\n",
      "Epoch:33 100/338 Loss:0.011\n",
      "Epoch:33 120/338 Loss:0.011\n",
      "Epoch:33 140/338 Loss:0.013\n",
      "Epoch:33 160/338 Loss:0.014\n",
      "Epoch:33 180/338 Loss:0.016\n",
      "Epoch:33 200/338 Loss:0.014\n",
      "Epoch:33 220/338 Loss:0.010\n",
      "Epoch:33 240/338 Loss:0.012\n",
      "Epoch:33 260/338 Loss:0.014\n",
      "Epoch:33 280/338 Loss:0.012\n",
      "Epoch:33 300/338 Loss:0.013\n",
      "Epoch:33 320/338 Loss:0.012\n",
      "Epoch:34 0/338 Loss:0.011\n",
      "Epoch:34 20/338 Loss:0.011\n",
      "Epoch:34 40/338 Loss:0.011\n",
      "Epoch:34 60/338 Loss:0.015\n",
      "Epoch:34 80/338 Loss:0.013\n",
      "Epoch:34 100/338 Loss:0.010\n",
      "Epoch:34 120/338 Loss:0.011\n",
      "Epoch:34 140/338 Loss:0.010\n",
      "Epoch:34 160/338 Loss:0.013\n",
      "Epoch:34 180/338 Loss:0.012\n",
      "Epoch:34 200/338 Loss:0.010\n",
      "Epoch:34 220/338 Loss:0.013\n",
      "Epoch:34 240/338 Loss:0.014\n",
      "Epoch:34 260/338 Loss:0.012\n",
      "Epoch:34 280/338 Loss:0.011\n",
      "Epoch:34 300/338 Loss:0.012\n",
      "Epoch:34 320/338 Loss:0.010\n",
      "Epoch:35 0/338 Loss:0.015\n",
      "Epoch:35 20/338 Loss:0.010\n",
      "Epoch:35 40/338 Loss:0.014\n",
      "Epoch:35 60/338 Loss:0.013\n",
      "Epoch:35 80/338 Loss:0.014\n",
      "Epoch:35 100/338 Loss:0.014\n",
      "Epoch:35 120/338 Loss:0.013\n",
      "Epoch:35 140/338 Loss:0.013\n",
      "Epoch:35 160/338 Loss:0.013\n",
      "Epoch:35 180/338 Loss:0.010\n",
      "Epoch:35 200/338 Loss:0.013\n",
      "Epoch:35 220/338 Loss:0.013\n",
      "Epoch:35 240/338 Loss:0.014\n",
      "Epoch:35 260/338 Loss:0.012\n",
      "Epoch:35 280/338 Loss:0.010\n",
      "Epoch:35 300/338 Loss:0.015\n",
      "Epoch:35 320/338 Loss:0.011\n",
      "Epoch:36 0/338 Loss:0.011\n",
      "Epoch:36 20/338 Loss:0.011\n",
      "Epoch:36 40/338 Loss:0.010\n",
      "Epoch:36 60/338 Loss:0.011\n",
      "Epoch:36 80/338 Loss:0.008\n",
      "Epoch:36 100/338 Loss:0.011\n",
      "Epoch:36 120/338 Loss:0.010\n",
      "Epoch:36 140/338 Loss:0.011\n",
      "Epoch:36 160/338 Loss:0.010\n",
      "Epoch:36 180/338 Loss:0.011\n",
      "Epoch:36 200/338 Loss:0.012\n",
      "Epoch:36 220/338 Loss:0.014\n",
      "Epoch:36 240/338 Loss:0.012\n",
      "Epoch:36 260/338 Loss:0.010\n",
      "Epoch:36 280/338 Loss:0.012\n",
      "Epoch:36 300/338 Loss:0.012\n",
      "Epoch:36 320/338 Loss:0.014\n",
      "Epoch:37 0/338 Loss:0.010\n",
      "Epoch:37 20/338 Loss:0.012\n",
      "Epoch:37 40/338 Loss:0.011\n",
      "Epoch:37 60/338 Loss:0.012\n",
      "Epoch:37 80/338 Loss:0.013\n",
      "Epoch:37 100/338 Loss:0.013\n",
      "Epoch:37 120/338 Loss:0.012\n",
      "Epoch:37 140/338 Loss:0.012\n",
      "Epoch:37 160/338 Loss:0.010\n",
      "Epoch:37 180/338 Loss:0.014\n",
      "Epoch:37 200/338 Loss:0.011\n",
      "Epoch:37 220/338 Loss:0.011\n",
      "Epoch:37 240/338 Loss:0.011\n",
      "Epoch:37 260/338 Loss:0.010\n",
      "Epoch:37 280/338 Loss:0.013\n",
      "Epoch:37 300/338 Loss:0.011\n",
      "Epoch:37 320/338 Loss:0.013\n",
      "Epoch:38 0/338 Loss:0.014\n",
      "Epoch:38 20/338 Loss:0.013\n",
      "Epoch:38 40/338 Loss:0.011\n",
      "Epoch:38 60/338 Loss:0.013\n",
      "Epoch:38 80/338 Loss:0.013\n",
      "Epoch:38 100/338 Loss:0.011\n",
      "Epoch:38 120/338 Loss:0.009\n",
      "Epoch:38 140/338 Loss:0.011\n",
      "Epoch:38 160/338 Loss:0.015\n",
      "Epoch:38 180/338 Loss:0.013\n",
      "Epoch:38 200/338 Loss:0.012\n",
      "Epoch:38 220/338 Loss:0.013\n",
      "Epoch:38 240/338 Loss:0.012\n",
      "Epoch:38 260/338 Loss:0.012\n",
      "Epoch:38 280/338 Loss:0.011\n",
      "Epoch:38 300/338 Loss:0.012\n",
      "Epoch:38 320/338 Loss:0.011\n",
      "Epoch:39 0/338 Loss:0.010\n",
      "Epoch:39 20/338 Loss:0.011\n",
      "Epoch:39 40/338 Loss:0.014\n",
      "Epoch:39 60/338 Loss:0.014\n",
      "Epoch:39 80/338 Loss:0.012\n",
      "Epoch:39 100/338 Loss:0.011\n",
      "Epoch:39 120/338 Loss:0.011\n",
      "Epoch:39 140/338 Loss:0.012\n",
      "Epoch:39 160/338 Loss:0.012\n",
      "Epoch:39 180/338 Loss:0.011\n",
      "Epoch:39 200/338 Loss:0.012\n",
      "Epoch:39 220/338 Loss:0.013\n",
      "Epoch:39 240/338 Loss:0.013\n",
      "Epoch:39 260/338 Loss:0.013\n",
      "Epoch:39 280/338 Loss:0.012\n",
      "Epoch:39 300/338 Loss:0.013\n",
      "Epoch:39 320/338 Loss:0.010\n",
      "Epoch:40 0/338 Loss:0.013\n",
      "Epoch:40 20/338 Loss:0.012\n",
      "Epoch:40 40/338 Loss:0.013\n",
      "Epoch:40 60/338 Loss:0.011\n",
      "Epoch:40 80/338 Loss:0.013\n",
      "Epoch:40 100/338 Loss:0.011\n",
      "Epoch:40 120/338 Loss:0.014\n",
      "Epoch:40 140/338 Loss:0.011\n",
      "Epoch:40 160/338 Loss:0.010\n",
      "Epoch:40 180/338 Loss:0.011\n",
      "Epoch:40 200/338 Loss:0.011\n",
      "Epoch:40 220/338 Loss:0.010\n",
      "Epoch:40 240/338 Loss:0.013\n",
      "Epoch:40 260/338 Loss:0.013\n",
      "Epoch:40 280/338 Loss:0.010\n",
      "Epoch:40 300/338 Loss:0.012\n",
      "Epoch:40 320/338 Loss:0.012\n",
      "Epoch:41 0/338 Loss:0.010\n",
      "Epoch:41 20/338 Loss:0.012\n",
      "Epoch:41 40/338 Loss:0.012\n",
      "Epoch:41 60/338 Loss:0.015\n",
      "Epoch:41 80/338 Loss:0.013\n",
      "Epoch:41 100/338 Loss:0.012\n",
      "Epoch:41 120/338 Loss:0.011\n",
      "Epoch:41 140/338 Loss:0.012\n",
      "Epoch:41 160/338 Loss:0.013\n",
      "Epoch:41 180/338 Loss:0.012\n",
      "Epoch:41 200/338 Loss:0.010\n",
      "Epoch:41 220/338 Loss:0.011\n",
      "Epoch:41 240/338 Loss:0.014\n",
      "Epoch:41 260/338 Loss:0.012\n",
      "Epoch:41 280/338 Loss:0.012\n",
      "Epoch:41 300/338 Loss:0.012\n",
      "Epoch:41 320/338 Loss:0.010\n",
      "Epoch:42 0/338 Loss:0.010\n",
      "Epoch:42 20/338 Loss:0.012\n",
      "Epoch:42 40/338 Loss:0.013\n",
      "Epoch:42 60/338 Loss:0.012\n",
      "Epoch:42 80/338 Loss:0.009\n",
      "Epoch:42 100/338 Loss:0.010\n",
      "Epoch:42 120/338 Loss:0.013\n",
      "Epoch:42 140/338 Loss:0.009\n",
      "Epoch:42 160/338 Loss:0.012\n",
      "Epoch:42 180/338 Loss:0.012\n",
      "Epoch:42 200/338 Loss:0.011\n",
      "Epoch:42 220/338 Loss:0.012\n",
      "Epoch:42 240/338 Loss:0.012\n",
      "Epoch:42 260/338 Loss:0.012\n",
      "Epoch:42 280/338 Loss:0.013\n",
      "Epoch:42 300/338 Loss:0.011\n",
      "Epoch:42 320/338 Loss:0.013\n",
      "Epoch:43 0/338 Loss:0.012\n",
      "Epoch:43 20/338 Loss:0.010\n",
      "Epoch:43 40/338 Loss:0.012\n",
      "Epoch:43 60/338 Loss:0.012\n",
      "Epoch:43 80/338 Loss:0.013\n",
      "Epoch:43 100/338 Loss:0.013\n",
      "Epoch:43 120/338 Loss:0.011\n",
      "Epoch:43 140/338 Loss:0.012\n",
      "Epoch:43 160/338 Loss:0.014\n",
      "Epoch:43 180/338 Loss:0.013\n",
      "Epoch:43 200/338 Loss:0.010\n",
      "Epoch:43 220/338 Loss:0.012\n",
      "Epoch:43 240/338 Loss:0.013\n",
      "Epoch:43 260/338 Loss:0.010\n",
      "Epoch:43 280/338 Loss:0.013\n",
      "Epoch:43 300/338 Loss:0.011\n",
      "Epoch:43 320/338 Loss:0.010\n",
      "Epoch:44 0/338 Loss:0.011\n",
      "Epoch:44 20/338 Loss:0.011\n",
      "Epoch:44 40/338 Loss:0.010\n",
      "Epoch:44 60/338 Loss:0.012\n",
      "Epoch:44 80/338 Loss:0.013\n",
      "Epoch:44 100/338 Loss:0.012\n",
      "Epoch:44 120/338 Loss:0.011\n",
      "Epoch:44 140/338 Loss:0.014\n",
      "Epoch:44 160/338 Loss:0.015\n",
      "Epoch:44 180/338 Loss:0.011\n",
      "Epoch:44 200/338 Loss:0.012\n",
      "Epoch:44 220/338 Loss:0.013\n",
      "Epoch:44 240/338 Loss:0.011\n",
      "Epoch:44 260/338 Loss:0.014\n",
      "Epoch:44 280/338 Loss:0.013\n",
      "Epoch:44 300/338 Loss:0.012\n",
      "Epoch:44 320/338 Loss:0.012\n",
      "Epoch:45 0/338 Loss:0.011\n",
      "Epoch:45 20/338 Loss:0.011\n",
      "Epoch:45 40/338 Loss:0.015\n",
      "Epoch:45 60/338 Loss:0.012\n",
      "Epoch:45 80/338 Loss:0.013\n",
      "Epoch:45 100/338 Loss:0.012\n",
      "Epoch:45 120/338 Loss:0.010\n",
      "Epoch:45 140/338 Loss:0.010\n",
      "Epoch:45 160/338 Loss:0.012\n",
      "Epoch:45 180/338 Loss:0.011\n",
      "Epoch:45 200/338 Loss:0.010\n",
      "Epoch:45 220/338 Loss:0.013\n",
      "Epoch:45 240/338 Loss:0.011\n",
      "Epoch:45 260/338 Loss:0.011\n",
      "Epoch:45 280/338 Loss:0.011\n",
      "Epoch:45 300/338 Loss:0.012\n",
      "Epoch:45 320/338 Loss:0.011\n",
      "Epoch:46 0/338 Loss:0.010\n",
      "Epoch:46 20/338 Loss:0.010\n",
      "Epoch:46 40/338 Loss:0.013\n",
      "Epoch:46 60/338 Loss:0.011\n",
      "Epoch:46 80/338 Loss:0.012\n",
      "Epoch:46 100/338 Loss:0.011\n",
      "Epoch:46 120/338 Loss:0.012\n",
      "Epoch:46 140/338 Loss:0.012\n",
      "Epoch:46 160/338 Loss:0.011\n",
      "Epoch:46 180/338 Loss:0.011\n",
      "Epoch:46 200/338 Loss:0.012\n",
      "Epoch:46 220/338 Loss:0.011\n",
      "Epoch:46 240/338 Loss:0.011\n",
      "Epoch:46 260/338 Loss:0.011\n",
      "Epoch:46 280/338 Loss:0.011\n",
      "Epoch:46 300/338 Loss:0.010\n",
      "Epoch:46 320/338 Loss:0.011\n",
      "Epoch:47 0/338 Loss:0.013\n",
      "Epoch:47 20/338 Loss:0.011\n",
      "Epoch:47 40/338 Loss:0.011\n",
      "Epoch:47 60/338 Loss:0.014\n",
      "Epoch:47 80/338 Loss:0.013\n",
      "Epoch:47 100/338 Loss:0.010\n",
      "Epoch:47 120/338 Loss:0.010\n",
      "Epoch:47 140/338 Loss:0.012\n",
      "Epoch:47 160/338 Loss:0.014\n",
      "Epoch:47 180/338 Loss:0.011\n",
      "Epoch:47 200/338 Loss:0.010\n",
      "Epoch:47 220/338 Loss:0.012\n",
      "Epoch:47 240/338 Loss:0.011\n",
      "Epoch:47 260/338 Loss:0.013\n",
      "Epoch:47 280/338 Loss:0.011\n",
      "Epoch:47 300/338 Loss:0.011\n",
      "Epoch:47 320/338 Loss:0.014\n",
      "Epoch:48 0/338 Loss:0.013\n",
      "Epoch:48 20/338 Loss:0.013\n",
      "Epoch:48 40/338 Loss:0.014\n",
      "Epoch:48 60/338 Loss:0.010\n",
      "Epoch:48 80/338 Loss:0.014\n",
      "Epoch:48 100/338 Loss:0.010\n",
      "Epoch:48 120/338 Loss:0.012\n",
      "Epoch:48 140/338 Loss:0.010\n",
      "Epoch:48 160/338 Loss:0.012\n",
      "Epoch:48 180/338 Loss:0.011\n",
      "Epoch:48 200/338 Loss:0.010\n",
      "Epoch:48 220/338 Loss:0.011\n",
      "Epoch:48 240/338 Loss:0.010\n",
      "Epoch:48 260/338 Loss:0.013\n",
      "Epoch:48 280/338 Loss:0.013\n",
      "Epoch:48 300/338 Loss:0.011\n",
      "Epoch:48 320/338 Loss:0.010\n",
      "Epoch:49 0/338 Loss:0.012\n",
      "Epoch:49 20/338 Loss:0.013\n",
      "Epoch:49 40/338 Loss:0.010\n",
      "Epoch:49 60/338 Loss:0.015\n",
      "Epoch:49 80/338 Loss:0.012\n",
      "Epoch:49 100/338 Loss:0.011\n",
      "Epoch:49 120/338 Loss:0.012\n",
      "Epoch:49 140/338 Loss:0.013\n",
      "Epoch:49 160/338 Loss:0.012\n",
      "Epoch:49 180/338 Loss:0.013\n",
      "Epoch:49 200/338 Loss:0.012\n",
      "Epoch:49 220/338 Loss:0.012\n",
      "Epoch:49 240/338 Loss:0.012\n",
      "Epoch:49 260/338 Loss:0.013\n",
      "Epoch:49 280/338 Loss:0.012\n",
      "Epoch:49 300/338 Loss:0.013\n",
      "Epoch:49 320/338 Loss:0.010\n"
     ]
    }
   ],
   "source": [
    "mask_ratio = 0.0\n",
    "max_traj_length = 5\n",
    "act_patch=config['Environment']['radius']*2//config['Environment']['grid_size']\n",
    "print(act_patch)\n",
    "\n",
    "log_iter_freq = 20\n",
    "imagine_freq = 2\n",
    "checkpoint = 20\n",
    "num_epoch = 50\n",
    "\n",
    "log = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    for n_iter, (img, target_id, fixations, correct, bbox) in enumerate(training_loader):\n",
    "\n",
    "        batch_size = img.shape[0]\n",
    "        #consistent with rl_rssm\n",
    "        env.set_data(img,target_id, bbox) #bbox->target bbox [x,y,w,h]\n",
    "\n",
    "        #start_time=time.time()\n",
    "        while env.step_id < max_traj_length-1:\n",
    "            '''Data generation'''\n",
    "            obs_before = env.observe()\n",
    "            #obs_before = Transpose(obs[0])\n",
    "            \n",
    "            #random step\n",
    "            act_batch = torch.randint(0, config['Environment']['grid_size']**2, (batch_size,)).to(device)\n",
    "            x=act_batch//config['Environment']['grid_size']\n",
    "            y=act_batch%config['Environment']['grid_size']\n",
    "            xy=torch.stack([x,y],dim=-1)\n",
    "            #print(x.item(),y.item())\n",
    "            #display(draw_focus(obs_before,x*act_patch,y*act_patch,act_patch))\n",
    "            obs_after, *_ = env.step(act_batch) #act_batch should shaped as [batch_size] scalars, and equals to x*grid_size + y\n",
    "            #display(Transpose(obs_after[0]))\n",
    "            \n",
    "            \n",
    "            '''train'''\n",
    "            encoded, batch_mask = mae_encoder.forward_encoder(obs_before, mask_ratio)\n",
    "            shifted = shift_block.forward_encoder(encoded, xy) #no cls_token\n",
    "            reconstructed = mae_decoder.forward_decoder(shifted[:, :, 1:], batch_mask, vis=True) #assume shift complete, deprive assistant dim\n",
    "\n",
    "            loss_rcs = mae_decoder.forward_loss(imgs=obs_after, pred=reconstructed, mask=batch_mask)\n",
    "            loss = loss_rcs #5*loss_cls + loss_rcs\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        #end_time=time.time()\n",
    "        #print(f'num_step_{max_traj_length} time: {end_time-start_time}')\n",
    "        \n",
    "        with torch.no_grad():   \n",
    "            if n_iter % log_iter_freq == 0:\n",
    "                print(f\"Epoch:{epoch} {n_iter}/{len(training_loader)} Loss:{loss.detach().item():.3f}\")\n",
    "                log.append(loss.detach().item())\n",
    "                #print(\"ACC:\",torch.sum(torch.argmax(target, dim=1)==torch.argmax(target_pred, dim=1))/target.shape[0])\n",
    "            if n_iter % checkpoint == 0  and n_iter != 0:\n",
    "                #torch.save(shift_block.state_dict(), \"./mae_log/shift_test/shift_param_coco.pth\")\n",
    "                torch.save(mae_decoder.state_dict(), \"./mae_log/shift_test/decoder_param_coco.pth\")\n",
    "                torch.save(log, \"./mae_log/shift_test/loss_coco_decoder_only.pt\")\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640e7383-f410-4660-915f-b0913a2de680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(114)\n",
    "x=np.expand_dims(np.random.randint(0,16,5),(0,1)).repeat(3,1).transpose(2,0,1)\n",
    "y=np.expand_dims(np.random.randint(0,16,5),(0,1)).repeat(3,1).transpose(2,0,1)\n",
    "xy=np.concatenate([x,y], axis=1)\n",
    "print(xy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e083ba2b-f377-4dfa-b564-99d4940e5ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "(5, 196, 1)\n",
      "[[10 12]\n",
      " [ 3  2]\n",
      " [ 6  8]\n",
      " [ 2  9]\n",
      " [11  3]]\n",
      "(5, 5, 196, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(114)\n",
    "#batch 20*20 512\n",
    "shift_token = np.zeros((5,196,512))\n",
    "shift_token[0,2,:]=1\n",
    "\n",
    "x = np.random.randint(0,14,5)\n",
    "y = np.random.randint(0,14,5)\n",
    "xy=np.stack([x,y],axis=1)\n",
    "print(xy.shape)\n",
    "xy_dot=x*14 + y\n",
    "xy_dot=np.tile(xy_dot,(1,196,1)).transpose()\n",
    "\n",
    "print(xy_dot.shape)\n",
    "print(xy)\n",
    "print(shift_token[:,xy_dot].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53cbcc-c16c-43a9-b9cd-fa5c6234a0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f6b39-c2fd-479f-9c44-2533a19a6483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
