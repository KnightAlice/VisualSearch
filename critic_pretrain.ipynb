{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e864605d-884a-4051-8bb3-07a9527bb8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5683d35-973d-4316-9414-8f7dfcd0f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import Critic,Critic_vgg, ACMerge_vgg, ACMerge_resnet\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plot\n",
    "import argparse\n",
    "import utils\n",
    "from torchvision.transforms import v2\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ad2dbc-1616-48b5-bbbe-c6f79c615257",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "parser = argparse.ArgumentParser(description='trainer')\n",
    "parser.add_argument('--lr', type=float, default=0.005, help='learning rate') \n",
    "parser.add_argument('--data_dir', default='archive', help='data directory')\n",
    "parser.add_argument('--batch_size', type=int, default=128,help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=50, help='total epochs to run')\n",
    "parser.add_argument('--verbose', type=int, default=1, help='verbose')\n",
    "parser.add_argument('--log_freq', type=int, default=50, help='loss print freq')\n",
    "parser.add_argument('--eval_freq', type=int, default=1, help='eval freq')\n",
    "parser.add_argument('--device', default='cuda', help='cuda')\n",
    "trainer_args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da96765a-2b8a-42b9-9bb9-46c175ddef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root=\"COCOSearch18\"\n",
    "with open(os.path.join(dataset_root,\n",
    "               'coco_search18_fixations_TP_train_split1.json'#'coco_search18_fixations_TP_train.json'\n",
    "               )) as json_file:\n",
    "    human_scanpaths_train = json.load(json_file)\n",
    "    \n",
    "with open(os.path.join(dataset_root,\n",
    "               'coco_search18_fixations_TP_validation_split1.json'#'coco_search18_fixations_TP_validation.json'\n",
    "               )) as json_file:\n",
    "    human_scanpaths_valid = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23cf1888-6f58-4f15-9630-eb4a9fc8cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=utils.COCOSearch18(json=human_scanpaths_train,root='COCOSearch18/images')\n",
    "validation_dataset=utils.COCOSearch18(json=human_scanpaths_valid,root='COCOSearch18/images')\n",
    "training_loader=DataLoader(train_dataset,batch_size=trainer_args.batch_size,shuffle=True,num_workers=8,drop_last=True)\n",
    "validation_loader=DataLoader(validation_dataset,batch_size=200,shuffle=True,num_workers=8,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38bb5519-b6e0-4d47-bdea-ba40b4fd449c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,Step:0,acc:0.090\n",
      "Epoch:0,Step:50,acc:0.795\n",
      "Epoch:0,Step:100,acc:0.780\n",
      "Epoch:0,Step:150,acc:0.795\n",
      "Epoch:1,Step:0,acc:0.835\n",
      "Epoch:1,Step:50,acc:0.785\n",
      "Epoch:1,Step:100,acc:0.865\n",
      "Epoch:1,Step:150,acc:0.800\n",
      "Epoch:2,Step:0,acc:0.860\n",
      "Epoch:2,Step:50,acc:0.855\n",
      "Epoch:2,Step:100,acc:0.795\n",
      "Epoch:2,Step:150,acc:0.815\n",
      "Epoch:3,Step:0,acc:0.840\n",
      "Epoch:3,Step:50,acc:0.845\n",
      "Epoch:3,Step:100,acc:0.855\n",
      "Epoch:3,Step:150,acc:0.835\n",
      "Epoch:4,Step:0,acc:0.845\n",
      "Epoch:4,Step:50,acc:0.795\n",
      "Epoch:4,Step:100,acc:0.785\n",
      "Epoch:4,Step:150,acc:0.800\n",
      "Epoch:5,Step:0,acc:0.775\n",
      "Epoch:5,Step:50,acc:0.745\n",
      "Epoch:5,Step:100,acc:0.785\n",
      "Epoch:5,Step:150,acc:0.850\n",
      "Epoch:6,Step:0,acc:0.825\n",
      "Epoch:6,Step:50,acc:0.755\n",
      "Epoch:6,Step:100,acc:0.850\n",
      "Epoch:6,Step:150,acc:0.800\n",
      "Epoch:7,Step:0,acc:0.835\n",
      "Epoch:7,Step:50,acc:0.815\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m acc_temp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trainer_args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (img, target_id, fixations, correct, bbox) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_loader):\n\u001b[1;32m     22\u001b[0m         center_x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mround(bbox[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mbbox[:,\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint)\n\u001b[1;32m     23\u001b[0m         center_y\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mround(bbox[:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mbbox[:,\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fovea_size=224\n",
    "save_path='./models/acmerge_resnet.pth'\n",
    "def tensor_to_PIL(tensor):\n",
    "    unloader = v2.ToPILImage()\n",
    "    image = tensor.cpu().clone()\n",
    "    image = image.squeeze(0)\n",
    "    image = unloader(image)\n",
    "    return image\n",
    "    \n",
    "#critic=Critic_vgg(weights=models.VGG16_Weights.IMAGENET1K_V1).to(trainer_args.device)#models.VGG16_Weights.IMAGENET1K_V1\n",
    "acmerge=ACMerge_resnet().to(trainer_args.device)#models.VGG16_Weights.IMAGENET1K_V1\n",
    "#print(acmerge.resnet.children)\n",
    "#raise ValueError\n",
    "#critic=Critic().to(trainer_args.device)\n",
    "optimizer=optim.Adam(params=acmerge.value_read_out.parameters(),lr=trainer_args.lr)\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "acc_temp=0\n",
    "\n",
    "for epoch in range(trainer_args.epochs):\n",
    "    for idx, (img, target_id, fixations, correct, bbox) in enumerate(training_loader):\n",
    "        \n",
    "        center_x=torch.round(bbox[:,0]+bbox[:,2]/2).to(torch.int)\n",
    "        center_y=torch.round(bbox[:,1]+bbox[:,3]/2).to(torch.int)\n",
    "        fix=torch.stack((center_x,center_y),dim=0).T\n",
    "        observation=[]\n",
    "        for i in range(trainer_args.batch_size):\n",
    "            height=fovea_size #fovea size\n",
    "            width=fovea_size\n",
    "            top=int(fix[i,1]-height/2)\n",
    "            left=int(fix[i,0]-width/2)\n",
    "            #print(top,left)\n",
    "            observation.append(v2.functional.crop(img[i],top,left,height,width)) #self-padding\n",
    "        sample=tensor_to_PIL(observation[0])\n",
    "        #plot.imshow(sample)\n",
    "        #plot.show()\n",
    "        observations=torch.stack(observation).to(trainer_args.device)\n",
    "        target_id=target_id.to(trainer_args.device)\n",
    "        optimizer.zero_grad()\n",
    "        _,output=acmerge(observations)\n",
    "        loss=loss_fn(output,target_id)+0.05*torch.norm(acmerge.value_read_out.weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            if idx%trainer_args.log_freq==0:\n",
    "\n",
    "                for valid_img, valid_target_id, _,_,valid_bbox in validation_loader:\n",
    "                    center_x=torch.round(valid_bbox[:,0]+valid_bbox[:,2]/2).to(torch.int)\n",
    "                    center_y=torch.round(valid_bbox[:,1]+valid_bbox[:,3]/2).to(torch.int)\n",
    "                    fix=torch.stack((center_x,center_y),dim=0).T\n",
    "                    valid_observation=[]\n",
    "                    for i in range(200):\n",
    "                        height=fovea_size #fovea size\n",
    "                        width=fovea_size\n",
    "                        top=int(fix[i,1]-height/2)\n",
    "                        left=int(fix[i,0]-width/2)\n",
    "                        #print(top,left)\n",
    "                        valid_observation.append(v2.functional.crop(valid_img[i],top,left,height,width)) #self-padding\n",
    "                    valid_observations=torch.stack(valid_observation).to(trainer_args.device)\n",
    "                    valid_target_id=valid_target_id.to(trainer_args.device)\n",
    "                    _,valid_output=acmerge(valid_observations)\n",
    "                    \n",
    "                    acc=torch.sum(torch.argmax(valid_output,dim=1)==valid_target_id)/200\n",
    "                    if acc>=acc_temp and epoch>=1:\n",
    "                        torch.save(acmerge.value_read_out.state_dict(),save_path)\n",
    "                        acc_temp=acc\n",
    "                    \n",
    "                    \n",
    "                    print(f'Epoch:{epoch},Step:{idx},acc:{acc:.3f}')\n",
    "                    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f1beb-9fcc-4e32-982a-ec7d51986d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
